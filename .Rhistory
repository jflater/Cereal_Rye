) %>%
filter(!needs_review)  # Optionally filter out rows needing review for separate handling
# Step 2: Filter and clean rows based on the comments column
df_cleaned <- df %>%
mutate(
# Standardize comments to lowercase for consistent handling
comment_number = tolower(comment_number),
# Add a flag for rows requiring attention based on comments
needs_review = if_else(str_detect(comment_number, "review|issue|error"), TRUE, FALSE)
) %>%
dplyr::filter(!needs_review)  # Optionally filter out rows needing review for separate handling
detach("package:stats", unload = TRUE)
library(readxl)
library(dplyr)
library(lubridate)
file_path <- "C:\Users\jflater\Box\CABBI\Data\MeasuredData\SABR\SmallDrainagePlots\Drainage\meter data\TileDrainage_2024.xlsx"
file_path <- "C:/Users/jflater/Box/CABBI/Data/MeasuredData/SABR/SmallDrainagePlots/Drainage/meter data/TileDrainage_2024.xlsx"
data <- read_excel(file_path, sheet = "Sheet1")
library(janitor)
data <- read_excel(file_path, sheet = "Sheet1") %>%
clean_names()
colnames(data)
library(readxl)
library(dplyr)
library(lubridate)
library(janitor)
file_path <- "C:/Users/jflater/Box/CABBI/Data/MeasuredData/SABR/SmallDrainagePlots/Drainage/meter data/TileDrainage_2024.xlsx"
data <- read_excel(file_path, sheet = "Sheet1") %>%
clean_names()
data <- data %>%
mutate(date = ymd(as.character(date)))
data <- data %>%
mutate(meter_reading = as.numeric(meter_reading))
data <- data %>%
mutate(sample_y_n = ifelse(sample_y_n == "Y", TRUE, False))
data <- data %>%
mutate(sample_y_n = ifelse(sample_y_n == "Y", TRUE, FALSE))
View(data)
# Load required libraries
library(readxl)
library(dplyr)
library(lubridate)
library(janitor)
# Define file path (Update this path as needed)
file_path <- "C:/Users/jflater/Box/CABBI/Data/MeasuredData/SABR/SmallDrainagePlots/Drainage/meter data/TileDrainage_2024.xlsx"
# Read data from Sheet1 and clean column names
data <- read_excel(file_path, sheet = "Sheet1") %>%
clean_names()
# Convert 'date' column from YYYYMMDD to Date format
data <- data %>%
mutate(date = ymd(as.character(date)))
# Ensure 'meter_reading' is numeric
data <- data %>%
mutate(meter_reading = as.numeric(meter_reading))
# Convert 'sample_y_n' to logical (TRUE/FALSE)
data <- data %>%
mutate(sample_y_n = ifelse(sample_y_n == "Y", TRUE, FALSE))
# Remove unnecessary columns or rows with all NA values
data <- data %>%
filter(!is.na(meter_reading))
# Define file path (Update this path as needed)
file_path <- "C:/Users/jflater/Box/CABBI/Data/MeasuredData/SABR/SmallDrainagePlots/Drainage/meter data/TileDrainage_2024.xlsx"
# Read data from Sheet1 and clean column names
data <- read_excel(file_path, sheet = "Sheet1") %>%
clean_names()
# Convert 'date' column from YYYYMMDD to Date format
data <- data %>%
mutate(date = ymd(as.character(date)))
# Ensure 'meter_reading' is numeric
data <- data %>%
mutate(meter_reading = as.numeric(meter_reading))
# Convert 'sample_y_n' to logical (TRUE/FALSE)
data <- data %>%
mutate(sample_y_n = ifelse(sample_y_n == "Y", TRUE, FALSE))
# Remove unnecessary columns or rows with all NA values
data <- data %>%
filter(!is.na(meter_reading))
View(data)
# Remove unnecessary columns or rows with all NA values
data <- data %>%
dplyr::filter(!is.na(meter_reading))
View(data)
# Sort data by plot and date
data <- data %>%
arrange(plot, date)
View(data)
# Calculate flow between readings
data <- data %>%
group_by(plot) %>%
mutate(flow = c(0, diff(meter_reading))) %>%  # First reading of each plot is set to 0
ungroup()
getwd()
# Save cleaned dataset with flow calculations to CSV
write.csv(data, "data/processed/Cleaned_Water_Meter_Data_2024.csv", row.names = FALSE)
# Print summary of cleaned data
print(summary(data))
# Load required libraries
library(readr)
library(lubridate)
library(dplyr)
# Define directory path containing .dat files
data_dir <- "C:/Users/jflater/Box/CABBI/Data/MeasuredData/SABR/LoggerAutoCollect/SABR_SmallDrainage_PitFlow_2025_01_23_0105"
# Get list of all .dat files in the directory
dat_files <- list.files(path = data_dir, pattern = "*.dat", full.names = TRUE)
# Function to read and process a single .dat file
read_logger_data <- function(file_path) {
data <- read_csv(file_path, skip = 4)  # Adjust skip based on header structure
# Convert date column (assuming first column is timestamp)
data <- data %>% mutate(Date = ymd_hms(data[[1]]))
# Clean column names
colnames(data) <- make.names(colnames(data))
return(data)
}
# Read and combine all .dat files
data_combined <- bind_rows(lapply(dat_files, read_logger_data))
library(readr)
library(lubridate)
library(dplyr)
# Define directory path containing .dat files
data_dir <- "C:/Users/jflater/Box/CABBI/Data/MeasuredData/SABR/LoggerAutoCollect/SABR_SmallDrainage_PitFlow_2025_01_23_0105"
# Get list of all .dat files in the directory
dat_files <- list.files(path = data_dir, pattern = "*.dat", full.names = TRUE)
# Select only the first two files for testing
dat_files <- dat_files[1:2]
# Function to read and process a single .dat file
read_logger_data <- function(file_path) {
data <- read_csv(file_path, skip = 4)  # Adjust skip based on header structure
# Convert date column (assuming first column is timestamp)
data <- data %>% mutate(Date = ymd_hms(data[[1]]))
# Clean column names
colnames(data) <- make.names(colnames(data))
return(data)
}
# Read and combine all .dat files
data_combined <- bind_rows(lapply(dat_files, read_logger_data))
# Save combined dataset to CSV
write_csv(data_combined, "data/processed/Logger_Combined_Data23to24.csv")
# Print summary
print(summary(data_combined))
View(data_combined)
# Load required libraries
library(readr)
library(lubridate)
library(dplyr)
# Define directory path containing .dat files
data_dir <- "C:/Users/jflater/Box/CABBI/Data/MeasuredData/SABR/LoggerAutoCollect/SABR_SmallDrainage_PitFlow_2025_01_23_0105"
# Get list of all .dat files in the directory
dat_files <- list.files(path = data_dir, pattern = "*.dat", full.names = TRUE)
# Select only the first two files for testing
dat_files <- dat_files[1:2]
# Function to read and process a single .dat file
read_logger_data <- function(file_path) {
data <- read_csv(file_path, skip = 3)  # Adjust skip based on header structure
# Convert date column (assuming first column is timestamp)
data <- data %>% mutate(Date = ymd_hms(data[[1]]))
# Clean column names
colnames(data) <- make.names(colnames(data))
return(data)
}
# Read and combine all .dat files
data_combined <- bind_rows(lapply(dat_files, read_logger_data))
# Save combined dataset to CSV
write_csv(data_combined, "data/processed/Logger_Combined_Data23to24.csv")
# Print summary
print(summary(data_combined))
View(data_combined)
# Load required libraries
library(readr)
library(lubridate)
library(dplyr)
# Define directory path containing .dat files
data_dir <- "C:/Users/jflater/Box/CABBI/Data/MeasuredData/SABR/LoggerAutoCollect/SABR_SmallDrainage_PitFlow_2025_01_23_0105"
# Get list of all .dat files in the directory
dat_files <- list.files(path = data_dir, pattern = "*.dat", full.names = TRUE)
# Select only the first two files for testing
dat_files <- dat_files[1:2]
# Function to read and process a single .dat file
read_logger_data <- function(file_path) {
data <- read_csv(file_path, skip = 3)  # Adjust skip based on header structure
# Convert date column (assuming first column is timestamp)
data <- data %>% mutate(Date = ymd_hms(data[[1]]))
# Clean column names
colnames(data) <- c("timestamp", "record_number", paste0("plot_", sprintf("%02d", 1:15)))
return(data)
}
# Read and combine all .dat files
data_combined <- bind_rows(lapply(dat_files, read_logger_data))
# Save combined dataset to CSV
write_csv(data_combined, "data/processed/Logger_Combined_Data23to24.csv")
# Print summary
print(summary(data_combined))
View(data_combined)
library(readr)
library(lubridate)
library(dplyr)
# Define directory path containing .dat files
data_dir <- "C:/Users/jflater/Box/CABBI/Data/MeasuredData/SABR/LoggerAutoCollect/SABR_SmallDrainage_PitFlow_2025_01_23_0105"
# Get list of all .dat files in the directory
dat_files <- list.files(path = data_dir, pattern = "*.dat", full.names = TRUE)
# Select only the first two files for testing
dat_files <- dat_files[1:2]
# Function to read and process a single .dat file
read_logger_data <- function(file_path) {
data <- read_csv(file_path, skip = 3)  # Adjust skip based on header structure
# Convert date column (assuming first column is timestamp)
# Clean column names
colnames(data) <- c("timestamp", "record_number", paste0("plot_", sprintf("%02d", 1:15)))
return(data)
}
# Read and combine all .dat files
data_combined <- bind_rows(lapply(dat_files, read_logger_data))
# Save combined dataset to CSV
write_csv(data_combined, "data/processed/Logger_Combined_Data23to24.csv")
# Print summary
print(summary(data_combined))
View(data_combined)
# Get list of all .dat files in the directory
dat_files <- list.files(path = data_dir, pattern = "*.dat", full.names = TRUE)
# Load required libraries
library(readr)
library(lubridate)
library(purr)
install.packages("purr")
install.packages("purrr")
install.packages("purrr")
library(readr)
library(lubridate)
library(purrr)
library(dplyr)
# Define directory path containing .dat files
data_dir <- "C:/Users/jflater/Box/CABBI/Data/MeasuredData/SABR/LoggerAutoCollect/SABR_SmallDrainage_PitFlow_2025_01_23_0105"
# Get list of all .dat files in the directory
dat_files <- list.files(path = data_dir, pattern = "*.dat", full.names = TRUE)
dat_files <- dat_files[1:2]  # For testing purposes, only read first two files
# Function to read and process a single .dat file
read_logger_data <- function(file_path) {
data <- read_csv(file_path, skip = 3)  # Adjust skip based on header structure
# Clean column names
colnames(data) <- c("timestamp", "record_number", paste0("plot_", sprintf("%02d", 1:15)))
return(data)
}
# Read and combine all .dat files
data_combined <- map_dfr(dat_files, read_logger_data)
# Save combined dataset to CSV
write_csv(data_combined, "data/processed/Logger_Combined_Data23to24.csv")
# Print summary
print(summary(data_combined))
View(data_combined)
# Load required libraries
library(readr)
library(lubridate)
library(purrr)
library(dplyr)
# Define directory path containing .dat files
data_dir <- "C:/Users/jflater/Box/CABBI/Data/MeasuredData/SABR/LoggerAutoCollect/SABR_SmallDrainage_PitFlow_2025_01_23_0105"
# Get list of all .dat files in the directory
dat_files <- list.files(path = data_dir, pattern = "*.dat", full.names = TRUE)
#dat_files <- dat_files[1:2]  # For testing purposes, only read first two files
# Function to read and process a single .dat file
read_logger_data <- function(file_path) {
data <- read_csv(file_path, skip = 3)  # Adjust skip based on header structure
# Clean column names
colnames(data) <- c("timestamp", "record_number", paste0("plot_", sprintf("%02d", 1:15)))
return(data)
}
# Read and combine all .dat files
data_combined <- map_dfr(dat_files, read_logger_data)
# Save combined dataset to CSV
write_csv(data_combined, "data/processed/Logger_Combined_Data23to24.csv")
# Print summary
print(summary(data_combined))
# Define path containing meter data .csv file
data_dir <- "data/processed/Logger_Combined_Data23to24.csv"
# Read data from CSV file
water_data <- read_csv(data_dir)
# Convert 'timestamp' column to POSIXct format
water_data <- water_data %>%
mutate(timestamp = ymd_hms(timestamp))
View(water_data)
gc()
library(lubridate)
library(tidyverse)
# Define path containing meter data .csv file
data_dir <- "data/processed/Logger_Combined_Data23to24.csv"
# Read data from CSV file
water_data <- read_csv(data_dir)
head(water_data)
head(water_data) %>%
mutate(ymd = ymd_hms(timestamp))
head(water_data) %>%
mutate(ymd = ymd_hms(timestamp)) %>%
select(ymd)
head(water_data) %>%
mutate(ymd = ymd(timestamp)) %>%
select(ymd)
head(water_data) %>%
mutate(ymd = ymd_hms(timestamp)) %>%
select(ymd)
head(water_data) %>%
mutate(ymd = ymd_hms(timestamp)) %>%
select(ymd(ymd))
head(water_data) %>%
mutate(test = ymd_hms(timestamp)) %>%
select(ymd(test))
head(water_data) %>%
mutate(test = ymd_hms(timestamp))
head(water_data) %>%
mutate(test = ymd_hms(timestamp)) %>%
select(ymd(test))
test <- head(water_data, 100)
View(test)
test <- head(water_data, 300)
View(test)
ymd(test$timestamp)
day(test$timestamp)
View(test)
water_data_long <- test %>%
pivot_longer(
cols = starts_with("plot_"),
names_to = "plot",
values_to = "flow"
) %>%
mutate(
plot = str_remove(plot, "plot_"),
plot = as.factor(plot)
)
View(water_data_long)
View(water_data_long)
class(water_data_long$timestamp)
water_data_long <- test %>%
pivot_longer(
cols = starts_with("plot_"),
names_to = "plot",
values_to = "flow"
) %>%
mutate(
plot = str_remove(plot, "plot_"),
plot = as.factor(plot),
date = as.Date(timestamp)
)
df <- test %>%
group_by(ymd(date), plot) %>%
summarise(flow = sum(flow))
ymd(water_data_long$date)
class(water_data_long$date)
class(ymd(water_data_long$date))
df <- test %>%
group_by(date, plot) %>%
summarise(flow = sum(flow))
df <- water_data_long %>%
group_by(date, plot) %>%
summarise(flow = sum(flow))
View(df)
water_data_long <- water_data %>%
pivot_longer(
cols = starts_with("plot_"),
names_to = "plot",
values_to = "flow"
) %>%
mutate(
plot = str_remove(plot, "plot_"),
plot = as.factor(plot),
date = as.Date(timestamp)
)
df <- water_data_long %>%
group_by(date, plot) %>%
summarise(flow = sum(flow))
View(df)
ggplot(df, aes(x = date, y = flow, color = plot)) +
geom_line() +
labs(title = "Flow over time",
x = "Date",
y = "Flow",
color = "Plot") +
theme_minimal()
ggplot(df, aes(x = date, y = flow, color = plot)) +
geom_line() +
labs(title = "Flow over time",
x = "Date",
y = "Flow",
color = "Plot") +
scale_x_date(date_breaks = "1 week", date_labels = "%Y-%m-%d") +
theme_minimal()
ggplot(df, aes(x = date, y = flow, color = plot)) +
geom_line() +
labs(title = "Flow over time",
x = "Date",
y = "Flow",
color = "Plot") +
scale_x_date(date_breaks = "1 week", date_labels = "%Y-%m-%d") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
theme_minimal()
ggplot(df, aes(x = date, y = flow, color = plot)) +
geom_line() +
labs(title = "Flow over time",
x = "Date",
y = "Flow",
color = "Plot") +
scale_x_date(date_breaks = "1 week", date_labels = "%Y-%m-%d") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
theme_minimal()
ggplot(df, aes(x = date, y = flow, color = plot)) +
geom_line() +
labs(title = "Flow over time",
x = "Date",
y = "Flow",
color = "Plot") +
scale_x_date(date_breaks = "1 week", date_labels = "%Y-%m-%d") +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
theme_minimal()
ggplot(df, aes(x = date, y = flow, color = plot)) +
geom_line() +
labs(title = "Flow over time",
x = "Date",
y = "Flow",
color = "Plot") +
scale_x_date(date_breaks = "1 week", date_labels = "%Y-%m-%d") +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
theme_minimal()
ggplot(df, aes(x = date, y = flow, color = plot)) +
geom_line() +
labs(title = "Flow over time",
x = "Date",
y = "Flow",
color = "Plot") +
scale_x_date(date_breaks = "1 week", date_labels = "%Y-%m-%d") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
df_may <- df %>%
filter(year(date) == 2024, month(date) == 5)
df_may <- water_data_long %>%
filter(year(date) == 2024, month(date) == 5)
class(water_data_long$date)
df_may <- water_data_long %>%
dplyr::filter(year(date) == 2024, month(date) == 5)
df_may <- df %>%
dplyr::filter(year(date) == 2024, month(date) == 5)
ggplot(df_may, aes(x = date, y = flow, color = plot)) +
geom_line() +
labs(title = "Flow over time",
x = "Date",
y = "Flow",
color = "Plot") +
scale_x_date(date_breaks = "1 week", date_labels = "%Y-%m-%d") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggplot(df_may, aes(x = date, y = flow, color = plot)) +
geom_line() +
labs(title = "Flow over time",
x = "Date",
y = "Flow",
color = "Plot") +
scale_x_date(date_breaks = "1 day", date_labels = "%Y-%m-%d") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# calculate cumulative flow for df_may using zoo package
library(zoo)
df_may_cum <- df_may %>%
group_by(plot) %>%
mutate(cum_flow = cumsum(flow))
View(df_may_cum)
ggplot(df_may_cum, aes(x = date, y = cum_flow, color = plot)) +
geom_line() +
labs(title = "Cumulative flow over time",
x = "Date",
y = "Cumulative Flow",
color = "Plot") +
scale_x_date(date_breaks = "1 day", date_labels = "%Y-%m-%d") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# place a label with the total flow for each plot
plot + geom_text(aes(label = cum_flow), hjust = 1, vjust = 1, nudge_x = 1, nudge_y = 1)
# Summarize the final cumulative flow for each plot
df_may_final <- df_may_cum %>%
group_by(plot) %>%
filter(date == max(date))  # Get the last recorded date for each plot
# Summarize the final cumulative flow for each plot
df_may_final <- df_may_cum %>%
group_by(plot) %>%
filter(date == max(.data$date))  # Get the last recorded date for each plot
df_may_cum <- df_may %>%
group_by(plot) %>%
mutate(cum_flow = cumsum(flow))
df_may_cum <- df_may_cum %>%
mutate(date = as.Date(date))  # Convert if necessary
df_may_final <- df_may_cum %>%
group_by(plot) %>%
filter(date == max(date, na.rm = TRUE))  # Ensure NA values don’t cause issues
df_may_final <- df_may_cum %>%
group_by(plot) %>%
dplyr::filter(date == max(date, na.rm = TRUE))  # Ensure NA values don’t cause issues
# Create the base plot
plot <- ggplot(df_may_cum, aes(x = date, y = cum_flow, color = plot)) +
geom_line() +
labs(title = "Cumulative Flow Over Time",
x = "Date",
y = "Cumulative Flow",
color = "Plot") +
scale_x_date(date_breaks = "1 day", date_labels = "%Y-%m-%d") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Add text labels for total cumulative flow at the last date for each plot
plot + geom_text(data = df_may_final, aes(label = round(cum_flow, 1)),
hjust = -0.2, vjust = -0.5, size = 4)
View(df)
################################################################################
########################################
# Create a data frame with weekly flow for each plot, ensuring year separation
weekly_flow <- df %>%
mutate(
year = year(date),
week = isoweek(date)  # ISO week number ensures correct week assignment
) %>%
group_by(year, week, plot) %>%
summarise(weekly_flow = sum(flow, na.rm = TRUE), .groups = "drop") %>%
arrange(year, week, plot)  # Ensure sorted order
View(weekly_flow)
